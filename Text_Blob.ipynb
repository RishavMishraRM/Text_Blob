{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rishav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Rishav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Rishav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rishav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "#import spacy\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob is python library nd offer  simple API to access its methods and perform basic NLP task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good thing about TextBlob is that they are just like python strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Edlightened\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic String Operation\n",
    "string1 = TextBlob(\"Edlightened - Knowledge Decode\")\n",
    "string1[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"EDLIGHTENED - KNOWLEDGE DECODE\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Edlightened - Knowledge Decode AIML\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2 = TextBlob(\"AIML\")\n",
    "string1 + \" \" + string2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textblob in c:\\users\\rishav\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in c:\\users\\rishav\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied, skipping upgrade: regex in c:\\users\\rishav\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from nltk>=3.1->textblob) (2020.10.28)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\rishav\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from nltk>=3.1->textblob) (4.50.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib in c:\\users\\rishav\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: click in c:\\users\\rishav\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"Edlightened is a great platform to learn data science.\"), Sentence(\"It helps community through blogs, hackathons, discussions, etc.\")]\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Edlightened is a great platform to learn data science. \\n It helps community through blogs, hackathons, discussions, etc.\")\n",
    "print(blob.sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization leads the sentence into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edlightened\n",
      "is\n",
      "a\n",
      "great\n",
      "platform\n",
      "to\n",
      "learn\n",
      "data\n",
      "science\n"
     ]
    }
   ],
   "source": [
    "for words in blob.sentences[0].words:\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enlightened\n",
      "great pltform\n",
      "data science\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Enlightened is a great pltform to learn data science\")\n",
    "for np in blob.noun_phrases:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enlightened VBN\n",
      "is VBZ\n",
      "a DT\n",
      "great JJ\n",
      "pltform NN\n",
      "to TO\n",
      "learn VB\n",
      "data NNS\n",
      "science NN\n"
     ]
    }
   ],
   "source": [
    "for words, tag in blob.tags:\n",
    "    print(words, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  This link would show what does this tags mean\n",
    "https://www.clips.uantwerpen.be/pages/mbsp-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helps\n",
      "help\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Edlightened is a great platform to learn Data Science. \\n It helps community through blogs, hackathons, discussions, etc\")\n",
    "print(blob.sentences[1].words[1])\n",
    "print(blob.sentences[1].words[1].singularize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob offers an object known word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Platforms'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "w = Word('Platform')\n",
    "w.pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use tags to inflect a particular words as shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platforms\n",
      "communities\n"
     ]
    }
   ],
   "source": [
    "for word, pos in blob.tags:\n",
    "    if pos == 'NN':\n",
    "        print(word.pluralize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words can be lemmatized using the lemmatize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word('running')\n",
    "w.lemmatize(\"v\") #v verb here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A combination of multiple words together are called N-Grams, N grams(N>1) are generally more informative as compared to words, and can be used as features for language modelling.\n",
    "N-grams can be easily accessed in TextBlob using ngrams function, which returns a tuple of n successive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Edlightened', 'is']\n",
      "['is', 'a']\n",
      "['a', 'great']\n",
      "['great', 'platform']\n",
      "['platform', 'to']\n",
      "['to', 'learn']\n",
      "['learn', 'Data']\n",
      "['Data', 'Science']\n",
      "['Science', 'It']\n",
      "['It', 'helps']\n",
      "['helps', 'community']\n",
      "['community', 'through']\n",
      "['through', 'blogs']\n",
      "['blogs', 'hackathons']\n",
      "['hackathons', 'discussions']\n",
      "['discussions', 'etc']\n"
     ]
    }
   ],
   "source": [
    "for ngram in blob.ngrams(2):\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sentiment analysis is basically the process of determning the attitude or the emotion of the writer, i.e., whether it is positive or negative or neutral. the sentiment function of textblob returns two properties, polarity, and subjectivity. Polarity is float which lies in range of [-1, 1] where 1 means a negative statement. Subjective sentence generally refers to personal opinnion, emotion or judgement whereas object refers to fctual informtion. Subjectivity is also  float which lies in range of [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edlightened is a great platform to learn Data Science. \n",
      " It helps community through blogs, hackathons, discussions, etc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.8, subjectivity=0.75)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(blob)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This throws polarity to 0.8 which means that statement is positive and 0.75 subjectivity refers the mostly it is public opinion and not  facctual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Enlightened is a great platform to learn data science\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spelling correction is feature which TextBlob offers, we can be accessed using the correct function as shown below\n",
    "blob = TextBlob('Edlightened is a gret platfor to learn data sciene')\n",
    "blob.correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We can check the list of suggested word  and its confidece using the spellcheck function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('platform', 1.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[4].spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####### Summary of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text is about...\n",
      "communities\n",
      "platforms\n",
      "platforms\n",
      "articles\n",
      "industries\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "blob = TextBlob('Edlightened is a thriving community for data driven industry. This platform allows \\\n",
    "people to know more about analytics form its article, Q&A forums, and learning paths. Also, we help \\\n",
    "professionals & amatures to sharpen their skillsets by providing a platform to participate in Hackathons.')\n",
    "nouns = list()\n",
    "for word, tag in blob.tags:\n",
    "    if tag == 'NN':\n",
    "        nouns.append(word.lemmatize())\n",
    "print(\"This text is about...\")\n",
    "for item in random.sample(nouns, 5):\n",
    "    word = Word(item)\n",
    "    print(word.pluralize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What we did above that we extracted out a list of nouns from text to give a gerneral idea to the the things that the text related to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"मैं यहां हूं\")\n",
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I am here\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.translate(from_lang='hi', to='en')\n",
    "blob.translate(to='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [\n",
    "(\"Tom Holland is a terrible spiderman.\",\"neg\"),\n",
    "(\"a terrible Javert (Russell Crowe) ruined Les Miserables for me...\",\"neg\"),\n",
    "(\"The Dark Knight Rises is the greatest superhero movie ever!\",\"pos\"),\n",
    "(\"Fantastic Four should have never been made.\",\"neg\"),\n",
    "(\"Wes Anderson is my favourite director!\",\"pos\"),\n",
    "(\"Captain America 2 is pretty awesome.\",\"pos\"),\n",
    "(\"Let\\s pretend 'Batman and Robin' never happened..\",\"neg\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = [\n",
    "(\"Superman was never an interesting character.\",\"neg\"),\n",
    "(\"Fantastic Mr Fox is an awesome film!\",\"pos\"),\n",
    "(\"Dragonball Evolution is simple terrible!!\",\"neg\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TextBlob provides in-build classifiers module to create a customer classifier. So let's quickly import it and create a basic classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import classifiers\n",
    "classifier = classifiers.NaiveBayesClassifier(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes classifier and TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = classifiers.DecisionTreeClassifier(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Most Informative Features\n",
      "            contains(is) = True              pos : neg    =      2.9 : 1.0\n",
      "             contains(a) = False             pos : neg    =      1.8 : 1.0\n",
      "         contains(never) = False             pos : neg    =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(classifier.accuracy(testing))\n",
    "classifier.show_informative_features(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob('The weather is Beautiful!', classifier = classifier)\n",
    "print(blob.classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
